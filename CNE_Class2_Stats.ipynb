{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNk+v6KHZ8wemk+fSKuzQAD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikislin/CNE25/blob/main/CNE_Class2_Stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical simulation tool.\n",
        "Features:\n",
        "- Interactive widgets for Normal, Ex-Gaussian, Shifted Log-Normal\n",
        "- Theoretical PDF plotted when available\n",
        "- Random seed control\n",
        "- Download generated sample as .npy or .csv\n"
      ],
      "metadata": {
        "id": "5Y7lTQ2crE64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import libraries and install missing\n",
        "# Install ipywidgets if necessary\n",
        "try:\n",
        "    from statsmodels.stats.power import TTestIndPower\n",
        "    import ipywidgets as widgets\n",
        "except ImportError:\n",
        "    import sys\n",
        "    print(\"Installing required libraries (statsmodels and ipywidgets)...\")\n",
        "    !{sys.executable} -m pip install --quiet statsmodels ipywidgets\n",
        "    from statsmodels.stats.power import TTestIndPower\n",
        "    import ipywidgets as widgets\n",
        "    print(\"Installation complete.\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interactive, Dropdown, IntSlider, FloatSlider, HBox, VBox, Button, Output\n",
        "from IPython.display import display, clear_output, Markdown\n",
        "from scipy import stats\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "UJglD1y48P_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Distribution definitions\n",
        "def normal_sample(size: int, loc: float, scale: float, seed: int = None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    return np.random.normal(loc=loc, scale=scale, size=size)\n",
        "\n",
        "def normal_pdf(x: np.ndarray, loc: float, scale: float):\n",
        "    return stats.norm.pdf(x, loc=loc, scale=scale)\n",
        "\n",
        "def exgaussian_sample(size: int, loc: float, scale: float, tau: float, seed: int = None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    return np.random.normal(loc=loc, scale=scale, size=size) + np.random.exponential(scale=tau, size=size)\n",
        "\n",
        "def shifted_lognormal_sample(size: int, mu: float, sigma: float, shift: float, seed: int = None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    return np.exp(np.random.normal(loc=mu, scale=sigma, size=size)) + shift\n",
        "\n",
        "def shifted_lognormal_pdf(x: np.ndarray, mu: float, sigma: float, shift: float):\n",
        "    out = np.zeros_like(x, dtype=float)\n",
        "    mask = x > shift\n",
        "    xm = x[mask] - shift\n",
        "    out[mask] = stats.lognorm.pdf(xm, s=sigma, scale=np.exp(mu))\n",
        "    return out\n",
        "\n",
        "def bernoulli_sample(size: int, p: float, seed: int = None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    return stats.bernoulli.rvs(p, size=size)\n",
        "\n",
        "def bernoulli_pdf(x: np.ndarray, p: float):\n",
        "    return stats.bernoulli.pmf(x, p)\n",
        "\n",
        "def betanbinom_sample(size: int, n: int, alpha: float, beta: float, seed: int = None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    p = stats.beta.rvs(alpha, beta)\n",
        "    return stats.nbinom.rvs(n, p, size=size)\n",
        "\n",
        "def f_sample(size: int, dfn: int, dfd: int, seed: int = None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    return stats.f.rvs(dfn, dfd, size=size)\n",
        "\n",
        "def f_pdf(x: np.ndarray, dfn: int, dfd: int):\n",
        "    return stats.f.pdf(x, dfn, dfd)\n",
        "\n",
        "def t_sample(size: int, df: int, seed: int = None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    return stats.t.rvs(df, size=size)\n",
        "\n",
        "def t_pdf(x: np.ndarray, df: int):\n",
        "    return stats.t.pdf(x, df)\n",
        "\n",
        "def z_sample(size: int, seed: int = None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    return stats.norm.rvs(size=size)\n",
        "\n",
        "def z_pdf(x: np.ndarray):\n",
        "    return stats.norm.pdf(x)\n",
        "\n",
        "def poisson_sample(size: int, lam: float, seed: int=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    return stats.poisson.rvs(mu=lam, size=size)\n",
        "\n",
        "def poisson_pdf(x: np.ndarray, lam: float):\n",
        "    return stats.poisson.pmf(x, mu=lam)\n",
        "\n",
        "def poisson_binomial_sample(size: int, probs: list, seed: int=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    trials = [stats.bernoulli.rvs(p, size=size) for p in probs]\n",
        "    return np.sum(trials, axis=0)\n"
      ],
      "metadata": {
        "id": "QleXcLxm8e4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title equations and linear models references\n",
        "# equations ------------------------------------------------------------------\n",
        "_equations = {\n",
        "    'Normal': r\"$f(x; \\mu, \\sigma) = \\\\frac{1}{\\\\sigma \\\\sqrt{2 \\\\pi}} e^{-\\\\frac{(x-\\\\mu)^2}{2\\\\sigma^2}}$\",\n",
        "    'Ex-Gaussian': r\"PDF omitted (convolution of Gaussian and Exponential)\",\n",
        "    'Shifted Log-Normal': r\"$f(x; \\\\mu, \\\\sigma, s) = \\\\frac{1}{(x-s)\\\\sigma \\\\sqrt{2 \\\\pi}} e^{-\\\\frac{(\\\\ln(x-s)-\\\\mu)^2}{2\\\\sigma^2}}, \\\\ x>s$\",\n",
        "    'Bernoulli': r\"$P(X=x) = p^x (1-p)^{1-x}, \\\\ x \\\\in {0,1}$\",\n",
        "    'Beta-Negative-Binomial': \"Beta prior on probability, mixture distribution (no simple closed-form PDF).\",\n",
        "    'F': r\"$f(x; d_1,d_2) = \\\\frac{1}{B(d_1/2, d_2/2)} (\\\\frac{d_1}{d_2})^{d_1/2} \\\\frac{x^{d_1/2 - 1}}{(1 + \\\\frac{d_1}{d_2}x)^{(d_1+d_2)/2}}$\",\n",
        "    't': r\"$f(x; \\\\nu) = \\\\frac{\\\\Gamma((\\\\nu+1)/2)}{\\\\sqrt{\\\\nu \\\\pi} \\\\Gamma(\\\\nu/2)} (1+\\\\frac{x^2}{\\\\nu})^{-(\\\\nu+1)/2}$\",\n",
        "    'Z (Standard Normal)': r\"$f(x) = \\\\frac{1}{\\\\sqrt{2\\\\pi}} e^{-x^2/2}$\"\n",
        "}\n",
        "\n",
        "# linear model equivalents in statsmodels formula style\n",
        "_linear_models = {\n",
        "    'Normal': \"smf.ols(formula='Y ~ 1', data=df).fit()\",\n",
        "    'Ex-Gaussian': \"Not directly in smf — mixture model; can be fit via MLE\",\n",
        "    'Shifted Log-Normal': \"smf.ols(formula='np.log(Y - shift) ~ X', data=df).fit()\",\n",
        "    'Bernoulli': \"smf.logit(formula='Y ~ X', data=df).fit()\",\n",
        "    'Beta-Negative-Binomial': \"GLM: smf.glm(formula='Y ~ X', family=sm.families.NegativeBinomial(), data=df).fit() with beta prior\",\n",
        "    'F': \"smf.ols(formula='Y ~ C(group)', data=df).fit(); sm.stats.anova_lm(model)\",\n",
        "    't': \"smf.ols(formula='Y ~ group', data=df).fit(); sm.stats.ttest_ind(...)\",\n",
        "    'Z (Standard Normal)': \"smf.ols(formula='Y ~ 1', data=df).fit(); z-test under known σ\",\n",
        "    'Poisson': \"smf.poisson(formula='Y ~ X', data=df).fit()\",\n",
        "    'Poisson-Binomial': \"Generalized model of independent Bernoulli trials; simulate via convolution, not in smf\"\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "a3N1jKj94lzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Widgets\n",
        "# Widget factory helpers -----------------------------------------------------\n",
        "def float_slider(value, min_, max_, step, description):\n",
        "    return FloatSlider(value=value, min=min_, max=max_, step=step, description=description, continuous_update=False)\n",
        "\n",
        "def int_slider(value, min_, max_, step, description):\n",
        "    return IntSlider(value=value, min=min_, max=max_, step=step, description=description, continuous_update=False)\n",
        "\n",
        "# Build distributions dict with widgets\n",
        "_distributions = {\n",
        "    'Normal': {\n",
        "        'sample_fn': normal_sample,\n",
        "        'param_widgets': {\n",
        "            'loc': float_slider(0.0, -5.0, 5.0, 0.1, 'μ (mean)'),\n",
        "            'scale': float_slider(1.0, 0.1, 5.0, 0.1, 'σ (std)')\n",
        "        },\n",
        "        'pdf_fn': normal_pdf\n",
        "    },\n",
        "    'Ex-Gaussian': {\n",
        "        'sample_fn': exgaussian_sample,\n",
        "        'param_widgets': {\n",
        "            'loc': float_slider(500.0, 100.0, 1000.0, 10.0, 'μ (mu)'),\n",
        "            'scale': float_slider(50.0, 10.0, 200.0, 5.0, 'σ (sigma)'),\n",
        "            'tau': float_slider(150.0, 50.0, 500.0, 10.0, 'τ (tau)')\n",
        "        },\n",
        "        'pdf_fn': None\n",
        "    },\n",
        "    'Shifted Log-Normal': {\n",
        "        'sample_fn': shifted_lognormal_sample,\n",
        "        'param_widgets': {\n",
        "            'mu': float_slider(6.0, 4.0, 8.0, 0.1, 'μ (log-mean)'),\n",
        "            'sigma': float_slider(0.4, 0.1, 2.0, 0.1, 'σ (log-std)'),\n",
        "            'shift': float_slider(200.0, 0.0, 500.0, 10.0, 'shift')\n",
        "        },\n",
        "        'pdf_fn': shifted_lognormal_pdf\n",
        "    },\n",
        "    'Bernoulli': {\n",
        "        'sample_fn': bernoulli_sample,\n",
        "        'param_widgets': {\n",
        "            'p': float_slider(0.5, 0.0, 1.0, 0.01, 'p')\n",
        "        },\n",
        "        'pdf_fn': bernoulli_pdf\n",
        "    },\n",
        "    'Beta-Negative-Binomial': {\n",
        "        'sample_fn': betanbinom_sample,\n",
        "        'param_widgets': {\n",
        "            'n': int_slider(10, 1, 100, 1, 'n'),\n",
        "            'alpha': float_slider(2.0, 0.1, 10.0, 0.1, 'alpha'),\n",
        "            'beta': float_slider(2.0, 0.1, 10.0, 0.1, 'beta')\n",
        "        },\n",
        "        'pdf_fn': None\n",
        "    },\n",
        "    'F': {\n",
        "        'sample_fn': f_sample,\n",
        "        'param_widgets': {\n",
        "            'dfn': int_slider(5, 1, 50, 1, 'dfn'),\n",
        "            'dfd': int_slider(10, 1, 50, 1, 'dfd')\n",
        "        },\n",
        "        'pdf_fn': f_pdf\n",
        "    },\n",
        "    't': {\n",
        "        'sample_fn': t_sample,\n",
        "        'param_widgets': {\n",
        "            'df': int_slider(10, 1, 100, 1, 'df')\n",
        "        },\n",
        "        'pdf_fn': t_pdf\n",
        "    },\n",
        "    'Z (Standard Normal)': {\n",
        "        'sample_fn': z_sample,\n",
        "        'param_widgets': {},\n",
        "        'pdf_fn': z_pdf\n",
        "    },\n",
        "    'Poisson': {\n",
        "        'sample_fn': poisson_sample,\n",
        "        'param_widgets': {'lam': float_slider(5.0, 0.1, 20.0, 0.1, 'λ')},\n",
        "        'pdf_fn': poisson_pdf\n",
        "    },\n",
        "    'Poisson-Binomial': {\n",
        "        'sample_fn': poisson_binomial_sample,\n",
        "        'param_widgets': {'p': float_slider(0.5, 0.0, 1.0, 0.01, 'p (equal)'),'k': int_slider(5, 1, 20, 1, 'n trials')},\n",
        "        'pdf_fn': None\n",
        "    }\n",
        "}\n",
        "\n",
        "# -- UI widgets ---------------------------------------------------------------\n",
        "dist_dropdown = Dropdown(options=list(_distributions.keys()), description='Distribution:')\n",
        "sample_size_slider = IntSlider(value=1000, min=50, max=20000, step=50, description='Sample Size:')\n",
        "seed_slider = IntSlider(value=0, min=0, max=2**31-1, step=1, description='Seed (0=none):')\n",
        "\n",
        "plot_output = Output()\n",
        "data_output = Output()\n",
        "controls_box = Output()\n",
        "\n",
        "generate_button = Button(description='Generate Data & Show Array', button_style='primary')\n",
        "download_npy_btn = Button(description='Download .npy')\n",
        "download_csv_btn = Button(description='Download .csv')\n",
        "export_dict_btn = Button(description='Export to Workspace Dict')\n",
        "\n",
        "_last_sample = {'data': None, 'params': None, 'dist': None}"
      ],
      "metadata": {
        "id": "JIH4_EnH8vkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Core\n",
        "\n",
        "def _get_param_values(dist_name: str):\n",
        "    widgets = _distributions[dist_name]['param_widgets']\n",
        "    return {k: w.value for k, w in widgets.items()}\n",
        "\n",
        "def _get_sample(dist_name: str, sample_size: int, seed: int, params: dict):\n",
        "    \"\"\"\n",
        "    Helper function to generate a sample, handling special cases like\n",
        "    the Poisson-Binomial distribution where widget parameters need to be\n",
        "    mapped to the sampling function's arguments.\n",
        "    \"\"\"\n",
        "    sample_fn = _distributions[dist_name]['sample_fn']\n",
        "\n",
        "    if dist_name == 'Poisson-Binomial':\n",
        "        # The widgets provide 'p' and 'k'. The function needs 'probs'.\n",
        "        # We create the 'probs' list from 'p' and 'k'.\n",
        "        p = params.get('p', 0.5)\n",
        "        k = params.get('k', 5)\n",
        "        probs = [p] * k\n",
        "        # Call the function with the correct argument name 'probs'.\n",
        "        return sample_fn(size=sample_size, probs=probs, seed=seed)\n",
        "    else:\n",
        "        # For all other distributions, pass parameters as they are.\n",
        "        return sample_fn(size=sample_size, seed=seed, **params)\n",
        "\n",
        "def _on_generate_clicked(_):\n",
        "    with data_output:\n",
        "        clear_output(wait=True)\n",
        "        dist_name = dist_dropdown.value\n",
        "        sample_size = sample_size_slider.value\n",
        "        seed = seed_slider.value\n",
        "        params = _get_param_values(dist_name)\n",
        "\n",
        "        # Use the new helper function to get the sample\n",
        "        sample = _get_sample(\n",
        "            dist_name=dist_name,\n",
        "            sample_size=sample_size,\n",
        "            seed=(None if seed == 0 else seed),\n",
        "            params=params\n",
        "        )\n",
        "\n",
        "        _last_sample['data'] = sample\n",
        "        _last_sample['params'] = params\n",
        "        _last_sample['dist'] = dist_name\n",
        "\n",
        "        print(f'Generated sample (first 20 of {sample_size}):')\n",
        "        np.set_printoptions(precision=6, suppress=True)\n",
        "        print(sample[:20])\n",
        "\n",
        "        # Summary statistics\n",
        "        print(\"\\nSummary statistics:\")\n",
        "        print(f\"Mean={np.mean(sample):.4f}, \"\n",
        "              f\"Variance={np.var(sample):.4f}, \"\n",
        "              f\"Skew={stats.skew(sample):.4f}, \"\n",
        "              f\"Kurtosis={stats.kurtosis(sample):.4f}\")\n",
        "\n",
        "        # Equation and LM equivalence\n",
        "        eqn = _equations.get(dist_name, \"\")\n",
        "        lm = _linear_models.get(dist_name, \"\")\n",
        "        display(Markdown(f\"**Equation:** {eqn}\"))\n",
        "        display(Markdown(f\"**Equivalent Linear Model:** {lm}\"))\n",
        "\n",
        "\n",
        "def _download_array_as_npy(_):\n",
        "    if _last_sample['data'] is None:\n",
        "        with data_output:\n",
        "            print('No data generated yet.')\n",
        "        return\n",
        "    filename = 'sample.npy'\n",
        "    np.save(filename, _last_sample['data'])\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(filename)\n",
        "    except Exception:\n",
        "        with data_output:\n",
        "            print(f'Saved to {filename} in the Colab filesystem.')\n",
        "\n",
        "\n",
        "def _download_array_as_csv(_):\n",
        "    if _last_sample['data'] is None:\n",
        "        with data_output:\n",
        "            print('No data generated yet.')\n",
        "        return\n",
        "    filename = 'sample.csv'\n",
        "    np.savetxt(filename, _last_sample['data'], delimiter=',')\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(filename)\n",
        "    except Exception:\n",
        "        with data_output:\n",
        "            print(f'Saved to {filename} in the Colab filesystem.')\n",
        "\n",
        "\n",
        "def _export_dict(_):\n",
        "    if _last_sample['data'] is None:\n",
        "        with data_output:\n",
        "            print('No data generated yet.')\n",
        "        return\n",
        "    export_obj = {\n",
        "        'distribution': _last_sample['dist'],\n",
        "        'parameters': _last_sample['params'],\n",
        "        'sample': _last_sample['data']\n",
        "    }\n",
        "    globals()['last_export'] = export_obj\n",
        "    with data_output:\n",
        "        print('Exported sample dictionary available as global variable `last_export`.')\n",
        "\n",
        "stats_output = Output()\n",
        "\n",
        "def update_plot(dist_name: str, sample_size: int, seed: int, **kwargs):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Use the new helper function to get the sample\n",
        "        sample = _get_sample(\n",
        "            dist_name=dist_name,\n",
        "            sample_size=sample_size,\n",
        "            seed=(None if seed == 0 else seed),\n",
        "            params=kwargs\n",
        "        )\n",
        "\n",
        "        # apply scientific style\n",
        "        plt.style.use('seaborn-v0_8-paper')\n",
        "        fig, axs = plt.subplots(2, 1, figsize=(6, 6), dpi=72,\n",
        "                                gridspec_kw={'height_ratios': [3, 1]})\n",
        "\n",
        "        # histogram\n",
        "        ax = axs[0]\n",
        "        ax.hist(sample, bins=50, density=True,\n",
        "                alpha=0.5, color=\"#4C72B0\", edgecolor=\"black\",\n",
        "                label='Histogram')\n",
        "\n",
        "        # theoretical PDF\n",
        "        pdf_fn = _distributions[dist_name]['pdf_fn']\n",
        "        if pdf_fn is not None:\n",
        "            xmin, xmax = np.nanmin(sample), np.nanmax(sample)\n",
        "            padding = (xmax - xmin) * 0.1 if xmax > xmin else 1.0\n",
        "            x = np.linspace(xmin - padding, xmax + padding, 800)\n",
        "            try:\n",
        "                p = pdf_fn(x, **kwargs) if dist_name != 'Z (Standard Normal)' else pdf_fn(x)\n",
        "                ax.plot(x, p, color='black', linewidth=2.0, label='Theoretical PDF')\n",
        "            except Exception as e:\n",
        "                print('Could not compute theoretical PDF:', e)\n",
        "\n",
        "        ax.set_title(f'{dist_name} (n={sample_size})', fontsize=14, weight='bold')\n",
        "        ax.set_xlabel('Value', fontsize=12)\n",
        "        ax.set_ylabel('Density', fontsize=12)\n",
        "        ax.tick_params(axis='both', labelsize=10)\n",
        "        ax.grid(True, linestyle=':', linewidth=0.7)\n",
        "        ax.legend(fontsize=10, frameon=False)\n",
        "\n",
        "        # horizontal boxplot\n",
        "        ax_box = axs[1]\n",
        "        boxprops = dict(facecolor=\"#DDDDDD\", color=\"black\", linewidth=1.2)\n",
        "        medianprops = dict(color=\"blue\", linewidth=2)\n",
        "        ax_box.boxplot(sample, vert=False, patch_artist=True,\n",
        "                       boxprops=boxprops, medianprops=medianprops)\n",
        "\n",
        "        # statistics\n",
        "        mean, median = np.mean(sample), np.median(sample)\n",
        "        q1, q3 = np.percentile(sample, [25, 75])\n",
        "        mode_val = stats.mode(sample, keepdims=True).mode[0]\n",
        "\n",
        "        # Confidence interval for the mean (95%)\n",
        "        sem = stats.sem(sample)\n",
        "        ci_low, ci_high = stats.norm.interval(0.95, loc=mean, scale=sem)\n",
        "        ax.axvline(mean, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Mean\")\n",
        "        ax.axvspan(ci_low, ci_high, color=\"red\", alpha=0.2, label=\"95% CI (mean)\")\n",
        "\n",
        "\n",
        "        # scatter markers\n",
        "        ax_box.scatter(mean, 1, color=\"red\", marker=\"D\", s=40, label=\"Mean\")\n",
        "        ax_box.scatter(median, 1, color=\"blue\", marker=\"s\", s=40, label=\"Median\")\n",
        "        ax_box.scatter(mode_val, 1, color=\"green\", marker=\"o\", s=40, label=\"Mode\")\n",
        "        ax_box.axvspan(q1, q3, color=\"yellow\", alpha=0.3, label=\"IQR\")\n",
        "\n",
        "        ax_box.set_xlabel('Value', fontsize=12)\n",
        "        ax_box.tick_params(axis='x', labelsize=10)\n",
        "        ax_box.legend(loc='lower center',ncol=4, fontsize=9, frameon=False)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # update memory\n",
        "        _last_sample['data'] = sample\n",
        "        _last_sample['params'] = kwargs\n",
        "        _last_sample['dist'] = dist_name\n",
        "\n",
        "    # update stats/equation/LM below plot\n",
        "    with stats_output:\n",
        "        clear_output(wait=True)\n",
        "        print(\"Summary statistics:\")\n",
        "        print(f\"Mean={mean:.4f}, Variance={np.var(sample):.4f}, \"\n",
        "              f\"Skew={stats.skew(sample):.4f}, Kurtosis={stats.kurtosis(sample):.4f}\")\n",
        "        eqn = _equations.get(dist_name, \"\")\n",
        "        lm = _linear_models.get(dist_name, \"\")\n",
        "        display(Markdown(f\"**Equation:** {eqn}\"))\n",
        "        display(Markdown(f\"**Equivalent Linear Model:** {lm}\"))\n"
      ],
      "metadata": {
        "id": "uJKgzDGH9zQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wire buttons\n",
        "generate_button.on_click(_on_generate_clicked)\n",
        "download_npy_btn.on_click(_download_array_as_npy)\n",
        "download_csv_btn.on_click(_download_array_as_csv)\n",
        "export_dict_btn.on_click(_export_dict)\n",
        "\n",
        "# -- Build and display UI ----------------------------------------------------\n",
        "def _render_controls(change=None):\n",
        "    with controls_box:\n",
        "        clear_output(wait=True)\n",
        "        dist_name = dist_dropdown.value\n",
        "        widgets_row = list(_distributions[dist_name]['param_widgets'].values())\n",
        "        header = HBox([dist_dropdown, sample_size_slider, seed_slider])\n",
        "        params_box = HBox(widgets_row)\n",
        "        buttons = HBox([generate_button, download_npy_btn, download_csv_btn, export_dict_btn])\n",
        "        display(VBox([header, params_box, buttons]))\n",
        "\n",
        "dist_dropdown.observe(_render_controls, names='value')\n",
        "_render_controls()\n",
        "\n",
        "_observed_widgets = [dist_dropdown, sample_size_slider, seed_slider]\n",
        "for dist in _distributions.values():\n",
        "    _observed_widgets.extend(list(dist['param_widgets'].values()))\n",
        "\n",
        "def _on_control_change(change):\n",
        "    dist_name = dist_dropdown.value\n",
        "    sample_size = sample_size_slider.value\n",
        "    seed = seed_slider.value\n",
        "    params = _get_param_values(dist_name)\n",
        "    update_plot(dist_name=dist_name,\n",
        "                sample_size=sample_size,\n",
        "                seed=seed, # seed is now passed directly\n",
        "                **params)"
      ],
      "metadata": {
        "id": "_YiHFSlLxYD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in _observed_widgets:\n",
        "    w.observe(_on_control_change, names='value')\n",
        "\n",
        "_on_control_change(None)\n",
        "\n",
        "ui = VBox([controls_box, plot_output, stats_output, data_output])\n",
        "display(ui)\n"
      ],
      "metadata": {
        "id": "H5qpPS498J3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = last_export\n",
        "print(sample_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "ezZ56HUI-Ihs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Central Limit Theorem"
      ],
      "metadata": {
        "id": "a2ydIfLIOx3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clt_demo_with_diagnostics(num_samples=1000, resample_size=30):\n",
        "    \"\"\"\n",
        "    Demonstrates the Central Limit Theorem using data from 'last_export',\n",
        "    and includes a goodness-of-fit test and a Q-Q plot to assess normality.\n",
        "\n",
        "    Args:\n",
        "        num_samples (int): The number of random subsamples to draw.\n",
        "        resample_size (int): The size of each subsample.\n",
        "    \"\"\"\n",
        "    # Check if the last_export variable exists and has data\n",
        "    if 'last_export' not in globals() or not isinstance(last_export, dict) or 'sample' not in last_export:\n",
        "        print(\"Please run the interactive widget and click 'Export to Workspace Dict' first.\")\n",
        "        return\n",
        "\n",
        "    original_sample = last_export['sample']\n",
        "    original_dist_name = last_export['distribution']\n",
        "\n",
        "    # Ensure the original sample is large enough for resampling\n",
        "    if len(original_sample) < resample_size:\n",
        "        print(f\"Warning: Original sample size ({len(original_sample)}) is smaller than the \"\n",
        "              f\"resample_size ({resample_size}). Try a smaller resample_size.\")\n",
        "        return\n",
        "\n",
        "    # Draw many sample means from the exported data using bootstrapping\n",
        "    sample_means = [\n",
        "        np.mean(np.random.choice(original_sample, size=resample_size, replace=True))\n",
        "        for _ in range(num_samples)\n",
        "    ]\n",
        "\n",
        "    # --- 1. Goodness-of-Fit Test (Shapiro-Wilk) ---\n",
        "    # This test checks the null hypothesis that the data was drawn from a normal distribution.\n",
        "    shapiro_stat, shapiro_p = stats.shapiro(sample_means)\n",
        "    fit_text = (f\"Shapiro-Wilk p-value: {shapiro_p:.4f}\\n\"\n",
        "                f\"(p > 0.05 suggests normality)\")\n",
        "\n",
        "\n",
        "    # --- 2. Create Plots (Histogram and Q-Q Plot) ---\n",
        "    plt.style.use('seaborn-v0_8-paper')\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5.5), dpi=100)\n",
        "    fig.suptitle(f\"Central Limit Theorem Diagnostics (Resampled from '{original_dist_name}')\", fontsize=16, weight='bold')\n",
        "\n",
        "\n",
        "    # --- Plot 1: Histogram of Sample Means ---\n",
        "    ax1.hist(sample_means, bins=40, density=True, alpha=0.7, color='skyblue',\n",
        "             edgecolor='black', label='Distribution of Sample Means')\n",
        "\n",
        "    # Overlay a normal distribution for comparison\n",
        "    mean_of_means, std_of_means = np.mean(sample_means), np.std(sample_means)\n",
        "    x = np.linspace(min(sample_means), max(sample_means), 200)\n",
        "    p = stats.norm.pdf(x, mean_of_means, std_of_means)\n",
        "    ax1.plot(x, p, 'r-', linewidth=2, label='Fitted Normal PDF')\n",
        "\n",
        "    ax1.set_title(f\"Distribution of {num_samples} Sample Means (n={resample_size})\", fontsize=12)\n",
        "    ax1.set_xlabel('Sample Mean Value', fontsize=10)\n",
        "    ax1.set_ylabel('Density', fontsize=10)\n",
        "    ax1.legend(frameon=False)\n",
        "    ax1.grid(True, linestyle=':', linewidth=0.7)\n",
        "    # Display the goodness-of-fit test result on the plot\n",
        "    ax1.text(0.05, 0.95, fit_text, transform=ax1.transAxes, fontsize=10,\n",
        "             verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.5))\n",
        "\n",
        "\n",
        "    # --- Plot 2: Q-Q Plot ---\n",
        "    stats.probplot(sample_means, dist=\"norm\", plot=ax2)\n",
        "    ax2.set_title(\"Q-Q Plot vs. Normal Distribution\", fontsize=12)\n",
        "    ax2.get_lines()[0].set_markerfacecolor('#4C72B0') # Change color of points\n",
        "    ax2.get_lines()[0].set_alpha(0.6)\n",
        "    ax2.get_lines()[1].set_color('red') # Change color of line\n",
        "    ax2.set_xlabel(\"Theoretical Quantiles\", fontsize=10)\n",
        "    ax2.set_ylabel(\"Sample Quantiles\", fontsize=10)\n",
        "    ax2.grid(True, linestyle=':', linewidth=0.7)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make room for suptitle\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "yJM6OaY7-sSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clt_demo_with_diagnostics(num_samples=2000, resample_size=50)"
      ],
      "metadata": {
        "id": "SQHd5H2KWC2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard Deviation (SD) vs. Standard Error of the Mean (SEM)\n",
        "\n",
        "Population Standard Deviation (SD):\n",
        "   A fixed measure of the spread of the entire population. In this demo, it will never change. It describes the variability of individual data points.\n",
        "\n",
        "Sample Standard Deviation (s):\n",
        "   An estimate of the population SD, calculated from a single sample. It will fluctuate from sample to sample.\n",
        "\n",
        "Standard Error of the Mean (SEM):\n",
        "   The standard deviation of the sampling distribution of the mean. It is not a measure of the data's spread, but a measure of the precision of the sample mean as an estimate of the population mean. You will see this shrink dramatically as sample size (n) increases."
      ],
      "metadata": {
        "id": "4Bq-1CLeFAaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Create a fixed, non-normal \"Population\" ---\n",
        "np.random.seed(42)\n",
        "population_size = 20000\n",
        "# Using a Gamma distribution makes it skewed and more realistic than a Normal distribution\n",
        "population = stats.gamma.rvs(a=2.5, scale=200, size=population_size)\n",
        "\n",
        "# Calculate the true, fixed population parameters\n",
        "POPULATION_MEAN = np.mean(population)\n",
        "POPULATION_SD = np.std(population)\n",
        "\n",
        "# --- 2. Setup the Interactive Widgets ---\n",
        "sample_size_slider = IntSlider(value=30, min=5, max=500, step=5, description='Sample Size (n):')\n",
        "draw_one_button = Button(description='Draw 1 Sample', button_style='info')\n",
        "draw_100_button = Button(description='Draw 100 Samples', button_style='primary')\n",
        "reset_button = Button(description='Reset Simulation', button_style='danger')\n",
        "\n",
        "# Use Output widgets to dynamically manage the plots\n",
        "plot_output = Output()\n",
        "stats_output = Output()\n",
        "\n",
        "# A list to store the means of the samples we draw\n",
        "sample_means = []\n",
        "\n",
        "# --- 3. Core Plotting and Logic Functions ---\n",
        "\n",
        "def update_plots():\n",
        "    \"\"\"Redraws both plots based on the current state of the simulation.\"\"\"\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), dpi=90, sharex=True)\n",
        "        plt.style.use('seaborn-v0_8-paper')\n",
        "\n",
        "        # --- Top Plot: Population and the most recent sample ---\n",
        "        ax1.hist(population, bins=60, density=True, color='gray', alpha=0.4, label='Population Distribution')\n",
        "        if 'last_sample' in globals() and last_sample is not None:\n",
        "            ax1.hist(last_sample, bins=20, density=True, color='skyblue', alpha=0.8, edgecolor='black', label=f'Most Recent Sample (n={len(last_sample)})')\n",
        "        ax1.axvline(POPULATION_MEAN, color='red', linestyle='--', lw=2, label=f'Population Mean (μ)')\n",
        "        ax1.legend(loc='center right')\n",
        "        ax1.set_title('1. Population Distribution & Drawn Samples', fontsize=14)\n",
        "        ax1.set_ylabel('Density')\n",
        "        # Display the fixed Population SD\n",
        "        ax1.text(0.98, 0.8, f'Population SD (σ): {POPULATION_SD:.2f}\\n(This value is fixed)',\n",
        "                 ha='right', transform=ax1.transAxes, bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.7))\n",
        "\n",
        "\n",
        "        # --- Bottom Plot: Sampling Distribution of the Mean ---\n",
        "        if len(sample_means) > 1:\n",
        "            ax2.hist(sample_means, bins=40, density=True, color='green', alpha=0.7, edgecolor='black', label='Sample Means')\n",
        "            # Overlay theoretical normal curve based on CLT\n",
        "            sem_theoretical = POPULATION_SD / np.sqrt(sample_size_slider.value)\n",
        "            x = np.linspace(min(sample_means), max(sample_means), 200)\n",
        "            ax2.plot(x, stats.norm.pdf(x, POPULATION_MEAN, sem_theoretical), 'k--', label='Theoretical (CLT)')\n",
        "        ax2.axvline(POPULATION_MEAN, color='red', linestyle='--', lw=2, label=f'Population Mean (μ)')\n",
        "        ax2.legend(loc='upper right')\n",
        "        ax2.set_title('2. Sampling Distribution of the Mean', fontsize=14)\n",
        "        ax2.set_xlabel('Value')\n",
        "        ax2.set_ylabel('Density')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def update_stats():\n",
        "    \"\"\"Updates the text display of statistics.\"\"\"\n",
        "    with stats_output:\n",
        "        clear_output(wait=True)\n",
        "        # --- Sample Stats ---\n",
        "        if 'last_sample' in globals() and last_sample is not None:\n",
        "            sample_sd = np.std(last_sample, ddof=1) # ddof=1 for sample SD\n",
        "            display(Markdown(f\"### Last Sample (n={len(last_sample)}):\"))\n",
        "            print(f\"  - Sample Mean (x̄): {np.mean(last_sample):.2f}\")\n",
        "            print(f\"  - Sample SD (s): {sample_sd:.2f} (Estimates the population SD)\")\n",
        "\n",
        "        # --- Sampling Distribution Stats ---\n",
        "        if len(sample_means) > 1:\n",
        "            sem_empirical = np.std(sample_means, ddof=1)\n",
        "            sem_theoretical = POPULATION_SD / np.sqrt(sample_size_slider.value)\n",
        "            display(Markdown(f\"### Sampling Distribution ({len(sample_means)} samples):\"))\n",
        "            print(f\"  - Mean of Sample Means: {np.mean(sample_means):.2f} (Approaching μ)\")\n",
        "            print(f\"  - SD of Sample Means (Empirical SEM): {sem_empirical:.2f}\")\n",
        "            print(f\"  - Theoretical SEM (σ/√n): {sem_theoretical:.2f}\")\n",
        "\n",
        "def draw_samples(num_to_draw):\n",
        "    \"\"\"Draws a specified number of samples and updates everything.\"\"\"\n",
        "    global last_sample\n",
        "    n = sample_size_slider.value\n",
        "    new_means = []\n",
        "    for _ in range(num_to_draw):\n",
        "        sample = np.random.choice(population, size=n, replace=True)\n",
        "        new_means.append(np.mean(sample))\n",
        "        last_sample = sample # Store the very last sample for plotting\n",
        "\n",
        "    sample_means.extend(new_means)\n",
        "    update_stats()\n",
        "    update_plots()\n",
        "\n",
        "# --- 4. Button Click Handlers ---\n",
        "def on_draw_one_clicked(b):\n",
        "    draw_samples(1)\n",
        "\n",
        "def on_draw_100_clicked(b):\n",
        "    draw_samples(100)\n",
        "\n",
        "def on_reset_clicked(b):\n",
        "    global last_sample, sample_means\n",
        "    last_sample = None\n",
        "    sample_means = []\n",
        "    update_stats()\n",
        "    update_plots()\n",
        "\n",
        "# Wire up the buttons to their functions\n",
        "draw_one_button.on_click(on_draw_one_clicked)\n",
        "draw_100_button.on_click(on_draw_100_clicked)\n",
        "reset_button.on_click(on_reset_clicked)\n",
        "\n",
        "# --- 5. Assemble and Display the UI ---\n",
        "controls = HBox([sample_size_slider, draw_one_button, draw_100_button, reset_button])\n",
        "ui = VBox([controls, stats_output, plot_output])\n",
        "\n",
        "display(Markdown(\"## Standard Deviation (SD) vs. Standard Error of the Mean (SEM)\"))\n",
        "display(Markdown(\n",
        "    \"This demo shows that the **Population SD is a fixed value**, while the **SEM depends on your sample size (`n`)**. \"\n",
        "    \"A larger `n` leads to a smaller SEM, meaning your sample mean is a more precise estimate of the true population mean.\"\n",
        "))\n",
        "\n",
        "display(ui)\n",
        "\n",
        "# Initial draw to populate the plots\n",
        "on_reset_clicked(None)"
      ],
      "metadata": {
        "id": "6ZYENy8DEWQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Type I and Type II errors in hypothesis testing"
      ],
      "metadata": {
        "id": "hwWlubdjO0Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type I error (α):\n",
        "\n",
        "A false positive. This occurs when a true null hypothesis is incorrectly rejected, leading to the false conclusion that a real effect or difference exists when it does not. The probability of making a Type I error is known as alpha (α) or the significance level.\n",
        "\n",
        "Type II error (β):\n",
        "\n",
        "A false negative. This occurs when a false null hypothesis is incorrectly not rejected, meaning a real effect or difference is missed. The probability of making a Type II error is known as beta (β)."
      ],
      "metadata": {
        "id": "VylfLBqYceWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Systematic Error: A consistent, predictable error that affects all measurements in the same way, often due to faulty equipment or methodology.\n",
        "\n",
        "\n",
        "Random Error: An unpredictable, uncontrolled variation in measurements that occurs due to chance.\n",
        "\n",
        "\n",
        "Measurement Error: Any error that occurs during the process of measuring a variable, encompassing both systematic and random errors.\n",
        "\n",
        "\n",
        "Sampling Error: An error that occurs because a sample is not perfectly representative of the entire population."
      ],
      "metadata": {
        "id": "rFchwDqjmwKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Part 1: The Visual Power Demo\n",
        "def visualize_power_tradeoffs(effect_size=0.5, sample_size=30, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Interactively demonstrates the factors affecting statistical power.\n",
        "    \"\"\"\n",
        "    df = (sample_size * 2) - 2\n",
        "    dist_H0 = stats.t(df=df)\n",
        "    ncp = effect_size * np.sqrt(sample_size / 2)\n",
        "    dist_H1 = stats.nct(df=df, nc=ncp)\n",
        "\n",
        "    plt.style.use('seaborn-v0_8-paper')\n",
        "    fig, ax = plt.subplots(figsize=(10, 6), dpi=90)\n",
        "    x = np.linspace(-5, 5 + effect_size * 2, 500)\n",
        "\n",
        "    ax.plot(x, dist_H0.pdf(x), color='gray', linestyle='--', label='H₀ Distribution (No Effect)')\n",
        "    ax.plot(x, dist_H1.pdf(x), color='green', label='H₁ Distribution (True Effect)')\n",
        "\n",
        "    critical_value = dist_H0.ppf(1 - alpha / 2)\n",
        "    power = 1 - dist_H1.cdf(critical_value) + dist_H1.cdf(-critical_value)\n",
        "\n",
        "    x_fill_power = np.linspace(critical_value, x.max(), 100)\n",
        "    ax.fill_between(x_fill_power, dist_H1.pdf(x_fill_power), color='#32CD32', alpha=0.6, label=f'Power (1-β = {power:.2f})')\n",
        "    x_fill_power_neg = np.linspace(x.min(), -critical_value, 100)\n",
        "    ax.fill_between(x_fill_power_neg, dist_H1.pdf(x_fill_power_neg), color='#32CD32', alpha=0.6)\n",
        "\n",
        "    x_fill_beta = np.linspace(-critical_value, critical_value, 200)\n",
        "    ax.fill_between(x_fill_beta, dist_H1.pdf(x_fill_beta), color='blue', alpha=0.4, label=f'Type II Error (β = {1-power:.2f})')\n",
        "\n",
        "    ax.axvline(critical_value, color='black', linestyle=':', lw=1.5, label=f'Critical Value (t={critical_value:.2f})')\n",
        "    ax.axvline(-critical_value, color='black', linestyle=':', lw=1.5)\n",
        "    ax.set_title(f'Statistical Power Analysis', fontsize=16, weight='bold')\n",
        "    ax.set_xlabel('t-Statistic', fontsize=12)\n",
        "    ax.set_ylabel('Probability Density', fontsize=12)\n",
        "    ax.legend(frameon=False, loc='upper left')\n",
        "    ax.grid(True, linestyle=':', alpha=0.6)\n",
        "    plt.ylim(0, 0.45)\n",
        "    plt.show()\n",
        "\n",
        "# --- 3. Part 2: The Corrected Practical Calculator ---\n",
        "def calculate_required_sample_size(effect_size=0.5, power=0.8, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Calculates the required sample size per group for a two-sample t-test\n",
        "    using the correct library: statsmodels.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # The key change is here: using TTestIndPower().solve_power\n",
        "        analysis = TTestIndPower()\n",
        "        required_n = analysis.solve_power(\n",
        "            effect_size=effect_size,\n",
        "            alpha=alpha,\n",
        "            power=power,\n",
        "            ratio=1.0,  # For equal group sizes\n",
        "            alternative='two-sided'\n",
        "        )\n",
        "        # We must have a whole number of participants\n",
        "        required_n = np.ceil(required_n)\n",
        "        print(f\"To achieve {power*100:.0f}% power with an effect size of {effect_size} and α={alpha},\")\n",
        "        print(f\"you need at least {int(required_n)} participants PER GROUP.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not calculate sample size. The required N may be too large for these parameters. Error: {e}\")\n",
        "\n",
        "# --- 4. Create and Display the Widgets ---\n",
        "\n",
        "# Visualizer Widget\n",
        "power_visualizer = interactive(\n",
        "    visualize_power_tradeoffs,\n",
        "    effect_size=FloatSlider(value=0.5, min=0.0, max=2.0, step=0.1, description='Effect Size (d):'),\n",
        "    sample_size=IntSlider(value=30, min=10, max=200, step=5, description='Sample Size (n):'),\n",
        "    alpha=FloatSlider(value=0.05, min=0.005, max=0.2, step=0.005, description='Alpha (α):', readout_format='.3f')\n",
        ")\n",
        "\n",
        "# Calculator Widget\n",
        "sample_size_calculator = interactive(\n",
        "    calculate_required_sample_size,\n",
        "    effect_size=FloatSlider(value=0.5, min=0.1, max=2.0, step=0.05, description='Effect Size (d):'),\n",
        "    power=FloatSlider(value=0.8, min=0.5, max=0.99, step=0.01, description='Desired Power:'),\n",
        "    alpha=FloatSlider(value=0.05, min=0.005, max=0.2, step=0.005, description='Alpha (α):', readout_format='.3f')\n",
        ")\n",
        "\n",
        "\n",
        "# Display everything with clear headings\n",
        "display(Markdown(\"### Part 1: Visualizing Power Trade-offs\"))\n",
        "display(power_visualizer)\n",
        "display(Markdown(\"\\n### Part 2: Required Sample Size Calculator\"))\n",
        "display(Markdown(\"This tool performs a prospective power analysis to help you plan an experiment.\"))\n",
        "display(sample_size_calculator)"
      ],
      "metadata": {
        "id": "YHkbe2MCSZLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pearson and Spearman correlation as linear models\n",
        "\n",
        "### Theory:\n",
        "\n",
        "**Model:** the recipe for $y$ is a slope ($\\beta_1$) times $x$ plus an intercept ($\\beta_0$, aka a straight line).\n",
        "\n",
        "$y = \\beta_0 + \\beta_1 x \\qquad \\mathcal{H}_0: \\beta_1 = 0$\n",
        "\n",
        "... which is a math-y way of writing the good old $y = ax + b$ (here ordered as $y = b + ax$). Using `patsy` lets us be a bit lazier and write `y ~ 1 + x` which reads like `y = 1 * number + x * othernumber`, and the task of linear models is simply to find the numbers that best predict `y`.\n",
        "\n",
        "Either way you write it, it's an intercept ($\\beta_0$) and a slope ($\\beta_1$) yielding a straight line:"
      ],
      "metadata": {
        "id": "Wob-fH1pDh8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title functions for linear models\n",
        "def linear_regression_plot():\n",
        "    # Construct data as a pd.DataFrame\n",
        "    x = np.random.normal(0, 2, 30)\n",
        "    y = 0.8 * x + 0.2 * 5 * np.random.randn(30)\n",
        "    df = pd.DataFrame()\n",
        "    df[\"x\"], df[\"y\"] = x, y\n",
        "\n",
        "    # Linear regression\n",
        "    res = smf.ols(\"y ~ 1 + x\", df).fit()\n",
        "    intercept, slope = res.params\n",
        "\n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=[5, 5])\n",
        "    ax.scatter(x, y, color=\"k\")\n",
        "    ax.axhline(intercept, color=\"b\", label=r\"$\\beta_0$ (Intercept)\")\n",
        "    ax.plot(\n",
        "        ax.get_xlim(),\n",
        "        [slope * x + intercept for x in ax.get_xlim()],\n",
        "        color=\"r\",\n",
        "        label=r\"$\\beta_1$ (Slope)\",\n",
        "    )\n",
        "    ax.legend()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "def pearson_spearman_plot():\n",
        "    # Construct data as pd.DataFrames\n",
        "    x = np.random.normal(0, 2, 30)\n",
        "    y = 0.8 * x + 0.2 * 5 * np.random.randn(30)\n",
        "    data_pearson = pd.DataFrame()\n",
        "    data_pearson[\"x\"], data_pearson[\"y\"] = x, y\n",
        "    data_spearman = data_pearson.rank()\n",
        "\n",
        "    # Pearson equivalent linear model\n",
        "    res_pearson = smf.ols(\"y ~ 1 + x\", data_pearson).fit()\n",
        "    intercept_pearson, slope_pearson = res_pearson.params\n",
        "\n",
        "    # Spearman equivalent linear model\n",
        "    res_spearman = smf.ols(\"y ~ 1 + x\", data_spearman).fit()\n",
        "    intercept_spearman, slope_spearman = res_spearman.params\n",
        "\n",
        "    # Plot\n",
        "    fig, axarr = plt.subplots(ncols=2, figsize=[18, 8])\n",
        "\n",
        "    for ax, dataset, to_str, title, a, b in zip(\n",
        "        axarr,\n",
        "        [data_pearson, data_spearman],\n",
        "        [format_decimals_factory(), format_decimals_factory(0)],\n",
        "        [\"Pearson\", \"Spearman\"],\n",
        "        [slope_pearson, slope_spearman],\n",
        "        [intercept_pearson, intercept_spearman],\n",
        "    ):\n",
        "        ax.scatter(dataset[\"x\"], dataset[\"y\"], color=\"k\")\n",
        "\n",
        "        annotations = (\n",
        "            \"(\" + dataset[\"x\"].apply(to_str) + \", \" + dataset[\"y\"].apply(to_str) + \")\"\n",
        "        )\n",
        "        for i, annot in enumerate(annotations):\n",
        "            ax.annotate(annot, (dataset[\"x\"][i], dataset[\"y\"][i]), color=\"grey\")\n",
        "\n",
        "        ax.axhline(a, color=\"b\", label=r\"$\\beta_0$ (Intercept)\")\n",
        "        ax.plot(\n",
        "            ax.get_xlim(),\n",
        "            [a * x + b for x in ax.get_xlim()],\n",
        "            color=\"r\",\n",
        "            label=r\"$\\beta_1$ (Slope)\",\n",
        "        )\n",
        "\n",
        "        ax.set_title(title)\n",
        "        ax.legend(fontsize=\"large\")\n",
        "\n",
        "    return fig, axarr\n",
        "\n",
        "def format_decimals_factory(num_decimals=1):\n",
        "    return lambda x: \"{1:.{0}f}\".format(num_decimals, x)\n",
        "\n",
        "def pairs_wilcoxon_plot():\n",
        "    # Construct data as a pd.DataFrame\n",
        "    y = np.random.normal(2, 1, 20)\n",
        "    y2 = y + np.random.randn(20)\n",
        "    df = pd.DataFrame()\n",
        "    df[\"y\"], df[\"y2\"], df[\"y_sub_y2\"] = y, y2, y - y2\n",
        "\n",
        "    # Wilcoxon equivalent linear model\n",
        "    res = smf.ols(formula=\"y_sub_y2 ~ 1\", data=df).fit()\n",
        "    intercept_wilcoxon = res.params.Intercept\n",
        "\n",
        "    # Plot\n",
        "    fig, axarr = plt.subplots(ncols=2, figsize=[18, 8])\n",
        "\n",
        "    # Left hand figure\n",
        "    axarr[0].scatter(np.zeros_like(df.y), df.y.values, color=\"k\")\n",
        "    axarr[0].scatter(np.ones_like(df.y2), df.y2.values, color=\"k\")\n",
        "\n",
        "    for i, j in zip(df.y, df.y2):\n",
        "        axarr[0].plot([0, 1], [i, j], color=\"k\")\n",
        "\n",
        "    axarr[0].set_title(\"Pairs\")\n",
        "\n",
        "    # Right hand figure\n",
        "    axarr[1].scatter(np.zeros_like(df.y_sub_y2), df.y_sub_y2.values, color=\"k\")\n",
        "\n",
        "    annotations = df.y_sub_y2.apply(format_decimals_factory())\n",
        "    for i, annot in enumerate(annotations):\n",
        "        axarr[1].annotate(annot, (0, df.y_sub_y2[i]), color=\"grey\")\n",
        "\n",
        "    axarr[1].axhline(intercept_wilcoxon, color=\"b\", label=r\"$\\beta_0$ (Intercept)\")\n",
        "\n",
        "    axarr[1].set_title(\"$t$-test\")\n",
        "    axarr[1].legend(fontsize=\"large\")\n",
        "\n",
        "    return fig, axarr\n",
        "\n",
        "def tabulate_results(test_values, ols_results, names, coeff=\"x\"):\n",
        "    \"\"\"\n",
        "    Tabulates results of statistical tests and equivalent linear regressions to\n",
        "    demonstrate that the two methods are in fact equivalent.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    test_values : list\n",
        "        List of values from the scipy statistical test to display.\n",
        "    ols_results : statsmodels.RegressionResults or list thereof\n",
        "        Result object(s) of equivalent linear regression to display.\n",
        "    names : list\n",
        "        List of strings to display.\n",
        "    coeff : str\n",
        "        Name of coefficient whose test statistics should be displayed. Defaults\n",
        "        to \"x\".\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    table : pd.DataFrame\n",
        "    \"\"\"\n",
        "    # There may be only one OLS result. If so, wrap it up as a single list.\n",
        "    if not isinstance(ols_results, list):\n",
        "        ols_results = [ols_results]\n",
        "\n",
        "    # Assert shapes\n",
        "    assert len(test_values) == 5\n",
        "    assert len(names) == len(ols_results) + 1\n",
        "\n",
        "    # Construct and return table\n",
        "    table = pd.DataFrame(index=names)\n",
        "    table[\"value\"] = [test_values[0]] + [res.params[coeff] for res in ols_results]\n",
        "    table[\"p-values\"] = [test_values[1]] + [res.pvalues[coeff] for res in ols_results]\n",
        "    table[\"t-values\"] = [test_values[2]] + [res.tvalues[coeff] for res in ols_results]\n",
        "    table[\"0.025 CI\"] = [test_values[3]] + [\n",
        "        res.conf_int().loc[coeff, 0] for res in ols_results\n",
        "    ]\n",
        "    table[\"0.975 CI\"] = [test_values[4]] + [\n",
        "        res.conf_int().loc[coeff, 1] for res in ols_results\n",
        "    ]\n",
        "\n",
        "    return table\n",
        "\n",
        "def signed_rank(df):\n",
        "    return np.sign(df) * df.abs().rank()\n",
        "\n"
      ],
      "metadata": {
        "id": "2VynUPSDC9KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression_plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z_vT3lMhC-BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is often simply called a *regression* model which can be extended to *multiple regression* where there are several $\\beta$s and on the right-hand side multiplied with the predictors. Everything below, from one-sample t-test to two-way ANOVA are just special cases of this system. Nothing more, nothing less.\n",
        "\n",
        "As the name implies, the *Spearman rank correlation* is a *Pearson correlation* on rank-transformed $x$ and $y$:\n",
        "\n",
        "$\\text{rank}(y) = \\beta_0 + \\beta_1 \\cdot \\text{rank}(x) \\qquad \\mathcal{H}_0: \\beta_1 = 0$\n",
        "\n",
        "Theory: rank-transformation\n",
        "\n",
        "`scipy.stats.rankdata` simply takes an array of numbers and \"replaces\" them with the integers of their rank (1st smallest, 2nd smallest, 3rd smallest, etc.). `pd.DataFrame.rank` performs a similar function, but with support for `pandas.DataFrames`. So the result of the rank-transformation `scipy.stats.rankdata([3.6, 3.4, -5.0, 8.2])` is `[3, 2, 1, 4]`. See that in the figure above?\n",
        "\n",
        "A _signed_ rank is the same, just where we rank according to absolute size first and then add in the sign second. So the signed rank here would be `[2, 1, -3, 4]`. Or in code:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def signed_rank(df):\n",
        "    return np.sign(df) * df.abs().rank()\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "0rg2Kt3vJlrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pearson_spearman_plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HGPOosPaDDRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It couldn't be much simpler to run these models with `statsmodels` ([`smf.ols`](https://www.statsmodels.org/stable/example_formulas.html#ols-regression-using-formulas)) or `scipy` ([`scipy.stats.pearson`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html)). They yield identical slopes, `p` and `t` values, but there's a catch: `smf.ols` gives you the *slope* and even though that is usually much more interpretable and informative than the _correlation coefficient_ $r$, you may still want $r$. Luckily, the slope becomes $r$ if `x` and `y` have a standard deviation of exactly 1. You can do this by scaling the data: `data /= data.std()`.\n",
        "\n",
        "Notice how `scipy.stats.pearsonr` and `smf.ols (scaled)` have the same slopes, $p$ and $t$ values. Also note that statistical functions from `scipy.stats` do not provide confidence intervals, while performing the linear regression with `smf.ols` does."
      ],
      "metadata": {
        "id": "vLMzzOciFOT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlated = pd.DataFrame()\n",
        "correlated[\"x\"] = np.linspace(0, 1)\n",
        "correlated[\"y\"] = 1.5 * correlated.x + 2 * np.random.randn(len(correlated.x))\n",
        "\n",
        "scaled = correlated / correlated.std()\n",
        "\n",
        "r, p = scipy.stats.pearsonr(correlated[\"x\"], correlated[\"y\"])\n",
        "res1 = smf.ols(formula=\"y ~ 1 + x\", data=correlated).fit()\n",
        "res2 = smf.ols(formula=\"y ~ 1 + x\", data=scaled).fit()"
      ],
      "metadata": {
        "id": "VZkchDDHEjTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabulate_results([r, p, None, None, None],\n",
        "                       [res1, res2],\n",
        "                       [\"scipy.stats.pearsonr\", \"smf.ols\", \"smf.ols (scaled)\"])"
      ],
      "metadata": {
        "id": "d-qzV-n8Ej37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranked = correlated.rank()\n",
        "\n",
        "r, p = scipy.stats.spearmanr(ranked[\"x\"], ranked[\"y\"])\n",
        "res = smf.ols(formula=\"y ~ 1 + x\", data=ranked).fit()"
      ],
      "metadata": {
        "id": "0_wBDCQTE73J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabulate_results([r, p, None, None, None],\n",
        "                       res,\n",
        "                       [\"scipy.stats.spearmanr\", \"smf.ols (ranked)\"])"
      ],
      "metadata": {
        "id": "bSp79_L_Lckv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common statistical tests are linear models\n"
      ],
      "metadata": {
        "id": "4C4PDauoLk-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paired samples t-test and Wilcoxon matched pairs"
      ],
      "metadata": {
        "id": "QVnqQry2Fkqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate example data\n",
        "data = pd.DataFrame()\n",
        "data[\"x\"] = np.random.normal(loc=0.0, scale=1.0, size=50)  # Used in correlation where this is on x-axis\n",
        "data[\"y\"] = np.random.normal(loc=0.5, scale=1.0, size=50)  # Almost zero mean\n",
        "data[\"y2\"] = np.random.normal(loc=0.8, scale=1.0, size=50)  # Used in two means\n",
        "data[\"y_sub_y2\"] = data[\"y\"] - data[\"y2\"]\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "TZqb5oirFiy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rank the data to make it more general solution\n",
        "signed_rank_data = signed_rank(data)\n",
        "\n",
        "_, p = scipy.stats.wilcoxon(data.y)\n",
        "res = smf.ols(\"y ~ 1\", data=signed_rank_data).fit()"
      ],
      "metadata": {
        "id": "SL_JLejmGT1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabulate_results([None, p, None, None, None],\n",
        "                       res,\n",
        "                       [\"scipy.stats.wilcoxon\", \"smf.ols (y ~ 1, signed rank)\"],\n",
        "                       coeff=\"Intercept\")"
      ],
      "metadata": {
        "id": "NSCpRMt8GUS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "pairs_wilcoxon_plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nvL4quqKGgPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  One-way ANOVA and Kruskal-Wallis as linear models\n",
        "\n",
        "Theory:\n",
        "\n",
        "Model: One mean for each group predicts $y$.\n",
        "\n",
        "$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 +... \\qquad \\mathcal{H}_0: y = \\beta_0$\n",
        "\n",
        "where $x_i$ are indicators ($x=0$ or $x=1$) where at most one $x_i=1$ while all others are $x_i=0$.\n",
        "\n",
        "Notice how this is just \"more of the same\" of what we already did in other models above. When there are only two groups, this model is $y = \\beta_0 + \\beta_1*x$, i.e. the independent t-test. If there is only one group, it is $y = \\beta_0$, i.e. the one-sample t-test. This is easy to see in the visualization below - just cover up a few groups and see that it matches the other visualizations above."
      ],
      "metadata": {
        "id": "ZaXmkQ3ENpgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate example data\n",
        "num_points = 20\n",
        "\n",
        "a = np.random.normal(0.0, 1, num_points)\n",
        "b = np.random.normal(3.0, 1, num_points)\n",
        "c = np.random.normal(-1.5, 1, num_points)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df[\"y\"] = np.concatenate([a, b, c])\n",
        "df[\"group\"] = list(\"\".join([num_points * char for char in \"abc\"]))\n",
        "df = df.join(pd.get_dummies(df.group, prefix=\"group\", drop_first=True).astype(np.float64))\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cxvrQIAyGysl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-way ANOVA\n",
        "F, p = scipy.stats.f_oneway(a, b, c)\n",
        "res = smf.ols(\"y ~ 1 + group_b + group_c\", df).fit()\n",
        "table = pd.DataFrame(index=[\"F statistic\", \"p value\", \"df\"])\n",
        "table[\"scipy.stats.f_oneway\"] = [F, p, None]\n",
        "table[\"ols (y ~ 1 + group_b + group_c)\"] = [res.fvalue, res.f_pvalue, res.df_model]\n",
        "\n",
        "print (table.T)"
      ],
      "metadata": {
        "id": "iddHNTpJOQ4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tableOneway = sm.stats.anova_lm(res, typ=3) # Type 3 Anova DataFrame\n",
        "print(tableOneway)"
      ],
      "metadata": {
        "id": "IZiu55V4Oiij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kruskal-Wallis\n",
        "\n",
        "signed_rank_df = df.copy()\n",
        "signed_rank_df[\"y\"] = signed_rank(signed_rank_df[\"y\"])\n",
        "\n",
        "_, p = scipy.stats.kruskal(a, b, c)\n",
        "res = smf.ols(\"y ~ 1 + group_b + group_c\", signed_rank_df).fit()\n",
        "\n",
        "table = pd.DataFrame(index=[\"p value\", \"df\"])\n",
        "table[\"scipy.stats.kruskal\"] = [p, None]\n",
        "table[\"ols (y ~ 1 + group_b + group_c, signed rank)\"] = [res.f_pvalue, res.df_model]\n",
        "\n",
        "print(table.T)"
      ],
      "metadata": {
        "id": "Iq_7yKK8O-Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tableKW = sm.stats.anova_lm(res, typ=3) # Type 3 Anova DataFrame\n",
        "print(tableKW)"
      ],
      "metadata": {
        "id": "UXSNLMqtP_pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o79caEH5QGre"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}